{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B2r1WUviZMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCMFJ5vIjP1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "46e5b61c-388e-46a1-d5a1-7ab5a973e4ca"
      },
      "source": [
        "#parameters\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))\n",
        "print(np.shape(x_test))\n",
        "print(np.shape(y_test))\n",
        "\n",
        "#Image dataset dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "print(img_rows, img_cols)\n",
        "\n",
        "#Reshape the dataset to have a single colour channel\n",
        "x_train = x_train.reshape((x_train.shape[0], img_rows, img_cols, 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], img_rows, img_cols, 1))\n",
        "\n",
        "#One hot encode target values\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "#Convert from integers to floats to divide the pixel value from the max value\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalize to range 0-1\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "#Adding Random Noise\n",
        "noise_factor = 0.25\n",
        "\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
        "#y_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "#y_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "\n",
        "y_train_noisy = y_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=y_train.shape)\n",
        "y_test_noisy = y_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=y_test.shape)\n",
        "\n",
        "print(np.shape(x_train_noisy))\n",
        "print(np.shape(y_train_noisy))\n",
        "print(np.shape(x_test_noisy))\n",
        "print(np.shape(y_test_noisy))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "28 28\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daqOifbXlOll",
        "colab_type": "text"
      },
      "source": [
        "**Improving Model Accuracy**\n",
        "\n",
        "Solutions:\n",
        "  1. Add normalization\n",
        "  2. Increase Model depth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkAJQpuAmBwM",
        "colab_type": "text"
      },
      "source": [
        "Adding Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRNu-lnzlkmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBGjZQgDlf77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "afcad0ee-2688-46f5-873e-5baafc19987f"
      },
      "source": [
        "model.fit(x_train_noisy, y_train_noisy,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_noisy, y_test_noisy))\n",
        "\n",
        "score = model.evaluate(x_test_noisy, y_test_noisy, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('> %.3f' % (score[1] * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 62s 1ms/step - loss: 0.4485 - accuracy: 0.8353 - val_loss: 0.0656 - val_accuracy: 0.9243\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 0.2671 - accuracy: 0.8762 - val_loss: -0.0158 - val_accuracy: 0.9308\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 0.2413 - accuracy: 0.8634 - val_loss: -0.0998 - val_accuracy: 0.9346\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 0.2636 - accuracy: 0.8457 - val_loss: -0.0234 - val_accuracy: 0.9295\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 0.4672 - accuracy: 0.8195 - val_loss: 0.0035 - val_accuracy: 0.9094\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 62s 1ms/step - loss: 1.2941 - accuracy: 0.7545 - val_loss: 0.8260 - val_accuracy: 0.8206\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 3.1940 - accuracy: 0.7313 - val_loss: 1.4155 - val_accuracy: 0.8499\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 7.3728 - accuracy: 0.7220 - val_loss: 2.8309 - val_accuracy: 0.8298\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 60s 1ms/step - loss: 25.2977 - accuracy: 0.6865 - val_loss: 10.4315 - val_accuracy: 0.7777\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 61s 1ms/step - loss: 44.5539 - accuracy: 0.7123 - val_loss: 23.6597 - val_accuracy: 0.8197\n",
            "Test loss: 23.65970776062012\n",
            "Test accuracy: 0.8197000026702881\n",
            "> 81.970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsaH1raemOHf",
        "colab_type": "text"
      },
      "source": [
        "Increase Model depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N74v4y49mQt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6wuECTSZuL2y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ffff1b75-6a14-4c2c-ac7a-fd33566f48f8"
      },
      "source": [
        "model.fit(x_train_noisy, y_train_noisy,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_noisy, y_test_noisy))\n",
        "\n",
        "score = model.evaluate(x_test_noisy, y_test_noisy, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('> %.3f' % (score[1] * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.2381 - accuracy: 0.9097 - val_loss: 0.0592 - val_accuracy: 0.9321\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 110s 2ms/step - loss: 0.1179 - accuracy: 0.9311 - val_loss: -0.0239 - val_accuracy: 0.9308\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 111s 2ms/step - loss: 0.0353 - accuracy: 0.9294 - val_loss: -0.1554 - val_accuracy: 0.9410\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 110s 2ms/step - loss: -0.0599 - accuracy: 0.9222 - val_loss: -0.0981 - val_accuracy: 0.9368\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: -0.1520 - accuracy: 0.9159 - val_loss: 0.7841 - val_accuracy: 0.9229\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0280 - accuracy: 0.9020 - val_loss: -0.0701 - val_accuracy: 0.9213\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 109s 2ms/step - loss: 0.0663 - accuracy: 0.8997 - val_loss: -0.0722 - val_accuracy: 0.8795\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 110s 2ms/step - loss: -0.0362 - accuracy: 0.8942 - val_loss: -0.9936 - val_accuracy: 0.9329\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 111s 2ms/step - loss: -0.6627 - accuracy: 0.8952 - val_loss: -1.4160 - val_accuracy: 0.8825\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 111s 2ms/step - loss: 1.6448 - accuracy: 0.8849 - val_loss: 1.1665 - val_accuracy: 0.9145\n",
            "Test loss: 1.166466064453125\n",
            "Test accuracy: 0.9144999980926514\n",
            "> 91.450\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}